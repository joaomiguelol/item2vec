{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(os.path.join(config.data_processed_dir , 'train.parquet'))\n",
    "valid = pd.read_parquet(os.path.join(config.data_processed_dir , 'valid.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_parquet(os.path.join(config.data_raw_dir , 'articles.parquet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>...</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_no</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010017</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>11</td>\n",
       "      <td>Off White</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110065001</td>\n",
       "      <td>110065</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Clean Lingerie</td>\n",
       "      <td>B</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>61</td>\n",
       "      <td>Womens Lingerie</td>\n",
       "      <td>1017</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110065002</td>\n",
       "      <td>110065</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>Clean Lingerie</td>\n",
       "      <td>B</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>61</td>\n",
       "      <td>Womens Lingerie</td>\n",
       "      <td>1017</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105537</th>\n",
       "      <td>953450001</td>\n",
       "      <td>953450</td>\n",
       "      <td>5pk regular Placement1</td>\n",
       "      <td>302</td>\n",
       "      <td>Socks</td>\n",
       "      <td>Socks &amp; Tights</td>\n",
       "      <td>1010014</td>\n",
       "      <td>Placement print</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Socks Bin</td>\n",
       "      <td>F</td>\n",
       "      <td>Menswear</td>\n",
       "      <td>3</td>\n",
       "      <td>Menswear</td>\n",
       "      <td>26</td>\n",
       "      <td>Men Underwear</td>\n",
       "      <td>1021</td>\n",
       "      <td>Socks and Tights</td>\n",
       "      <td>Socks in a fine-knit cotton blend with a small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105538</th>\n",
       "      <td>953763001</td>\n",
       "      <td>953763</td>\n",
       "      <td>SPORT Malaga tank</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>2</td>\n",
       "      <td>H&amp;M+</td>\n",
       "      <td>1005</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Loose-fitting sports vest top in ribbed fast-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105539</th>\n",
       "      <td>956217002</td>\n",
       "      <td>956217</td>\n",
       "      <td>Cartwheel dress</td>\n",
       "      <td>265</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>18</td>\n",
       "      <td>Womens Trend</td>\n",
       "      <td>1005</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Short, A-line dress in jersey with a round nec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105540</th>\n",
       "      <td>957375001</td>\n",
       "      <td>957375</td>\n",
       "      <td>CLAIRE HAIR CLAW</td>\n",
       "      <td>72</td>\n",
       "      <td>Hair clip</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Small Accessories</td>\n",
       "      <td>D</td>\n",
       "      <td>Divided</td>\n",
       "      <td>2</td>\n",
       "      <td>Divided</td>\n",
       "      <td>52</td>\n",
       "      <td>Divided Accessories</td>\n",
       "      <td>1019</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Large plastic hair claw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105541</th>\n",
       "      <td>959461001</td>\n",
       "      <td>959461</td>\n",
       "      <td>Lounge dress</td>\n",
       "      <td>265</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>11</td>\n",
       "      <td>Off White</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>18</td>\n",
       "      <td>Womens Trend</td>\n",
       "      <td>1005</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Calf-length dress in ribbed jersey made from a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105542 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id  product_code               prod_name  product_type_no  \\\n",
       "0        108775015        108775               Strap top              253   \n",
       "1        108775044        108775               Strap top              253   \n",
       "2        108775051        108775           Strap top (1)              253   \n",
       "3        110065001        110065       OP T-shirt (Idro)              306   \n",
       "4        110065002        110065       OP T-shirt (Idro)              306   \n",
       "...            ...           ...                     ...              ...   \n",
       "105537   953450001        953450  5pk regular Placement1              302   \n",
       "105538   953763001        953763       SPORT Malaga tank              253   \n",
       "105539   956217002        956217         Cartwheel dress              265   \n",
       "105540   957375001        957375        CLAIRE HAIR CLAW               72   \n",
       "105541   959461001        959461            Lounge dress              265   \n",
       "\n",
       "       product_type_name  product_group_name  graphical_appearance_no  \\\n",
       "0               Vest top  Garment Upper body                  1010016   \n",
       "1               Vest top  Garment Upper body                  1010016   \n",
       "2               Vest top  Garment Upper body                  1010017   \n",
       "3                    Bra           Underwear                  1010016   \n",
       "4                    Bra           Underwear                  1010016   \n",
       "...                  ...                 ...                      ...   \n",
       "105537             Socks      Socks & Tights                  1010014   \n",
       "105538          Vest top  Garment Upper body                  1010016   \n",
       "105539             Dress   Garment Full body                  1010016   \n",
       "105540         Hair clip         Accessories                  1010016   \n",
       "105541             Dress   Garment Full body                  1010016   \n",
       "\n",
       "       graphical_appearance_name  colour_group_code colour_group_name  ...  \\\n",
       "0                          Solid                  9             Black  ...   \n",
       "1                          Solid                 10             White  ...   \n",
       "2                         Stripe                 11         Off White  ...   \n",
       "3                          Solid                  9             Black  ...   \n",
       "4                          Solid                 10             White  ...   \n",
       "...                          ...                ...               ...  ...   \n",
       "105537           Placement print                  9             Black  ...   \n",
       "105538                     Solid                  9             Black  ...   \n",
       "105539                     Solid                  9             Black  ...   \n",
       "105540                     Solid                  9             Black  ...   \n",
       "105541                     Solid                 11         Off White  ...   \n",
       "\n",
       "          department_name index_code        index_name index_group_no  \\\n",
       "0            Jersey Basic          A        Ladieswear              1   \n",
       "1            Jersey Basic          A        Ladieswear              1   \n",
       "2            Jersey Basic          A        Ladieswear              1   \n",
       "3          Clean Lingerie          B  Lingeries/Tights              1   \n",
       "4          Clean Lingerie          B  Lingeries/Tights              1   \n",
       "...                   ...        ...               ...            ...   \n",
       "105537          Socks Bin          F          Menswear              3   \n",
       "105538             Jersey          A        Ladieswear              1   \n",
       "105539             Jersey          A        Ladieswear              1   \n",
       "105540  Small Accessories          D           Divided              2   \n",
       "105541             Jersey          A        Ladieswear              1   \n",
       "\n",
       "        index_group_name section_no            section_name garment_group_no  \\\n",
       "0             Ladieswear         16  Womens Everyday Basics             1002   \n",
       "1             Ladieswear         16  Womens Everyday Basics             1002   \n",
       "2             Ladieswear         16  Womens Everyday Basics             1002   \n",
       "3             Ladieswear         61         Womens Lingerie             1017   \n",
       "4             Ladieswear         61         Womens Lingerie             1017   \n",
       "...                  ...        ...                     ...              ...   \n",
       "105537          Menswear         26           Men Underwear             1021   \n",
       "105538        Ladieswear          2                    H&M+             1005   \n",
       "105539        Ladieswear         18            Womens Trend             1005   \n",
       "105540           Divided         52     Divided Accessories             1019   \n",
       "105541        Ladieswear         18            Womens Trend             1005   \n",
       "\n",
       "        garment_group_name                                        detail_desc  \n",
       "0             Jersey Basic            Jersey top with narrow shoulder straps.  \n",
       "1             Jersey Basic            Jersey top with narrow shoulder straps.  \n",
       "2             Jersey Basic            Jersey top with narrow shoulder straps.  \n",
       "3        Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
       "4        Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
       "...                    ...                                                ...  \n",
       "105537    Socks and Tights  Socks in a fine-knit cotton blend with a small...  \n",
       "105538        Jersey Fancy  Loose-fitting sports vest top in ribbed fast-d...  \n",
       "105539        Jersey Fancy  Short, A-line dress in jersey with a round nec...  \n",
       "105540         Accessories                           Large plastic hair claw.  \n",
       "105541        Jersey Fancy  Calf-length dress in ribbed jersey made from a...  \n",
       "\n",
       "[105542 rows x 25 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14317/710849988.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  articles['text'] = articles['prod_name'] + ' ' + articles['detail_desc']\n",
      "/tmp/ipykernel_14317/710849988.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  articles['text'] = articles['text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# select only string columns\n",
    "# get names of s\n",
    "articles = articles[['article_id', 'prod_name', 'detail_desc']]\n",
    "\n",
    "# join prod_name and prod_desc\n",
    "articles['text'] = articles['prod_name'] + ' ' + articles['detail_desc']\n",
    "articles['text'] = articles['text'].str.lower()\n",
    "articles = articles[['article_id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the columns we need\n",
    "train = train[['customer_id', 'article_id']]\n",
    "valid = valid[['customer_id', 'article_id']]\n",
    "# concat train and valid\n",
    "train = pd.concat([train, valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby customer_id and aggregate article_id into a list, then split the lists into groups of 2 consecutive articles\n",
    "train = train.groupby('customer_id')['article_id'].agg(list).apply(lambda x: [x[i:i+2] for i in range(len(x)-1)]).explode().reset_index()\n",
    "train = train[train['article_id'].notna()]\n",
    "# explode article_id into 2 columns article_1 and article_2\n",
    "train = train.join(pd.DataFrame(train.pop('article_id').tolist(), columns=['article_1', 'article_2']))\n",
    "# drop na values again\n",
    "train = train[train['article_1'].notna()]\n",
    "train = train[train['article_2'].notna()]\n",
    "# drop rows where article_1 and article_2 are the same\n",
    "train = train[train['article_1'] != train['article_2']]\n",
    "train['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_1</th>\n",
       "      <th>article_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>599580055.0</td>\n",
       "      <td>811835004.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>811835004.0</td>\n",
       "      <td>723529001.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>723529001.0</td>\n",
       "      <td>559630026.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>559630026.0</td>\n",
       "      <td>599580083.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>599580083.0</td>\n",
       "      <td>811927004.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253154</th>\n",
       "      <td>1368904</td>\n",
       "      <td>884081001.0</td>\n",
       "      <td>794819001.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253155</th>\n",
       "      <td>1368904</td>\n",
       "      <td>794819001.0</td>\n",
       "      <td>762846027.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253156</th>\n",
       "      <td>1368904</td>\n",
       "      <td>866755002.0</td>\n",
       "      <td>840360003.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253157</th>\n",
       "      <td>1368904</td>\n",
       "      <td>840360003.0</td>\n",
       "      <td>866755002.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253158</th>\n",
       "      <td>1368904</td>\n",
       "      <td>866755002.0</td>\n",
       "      <td>882810001.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          customer_id    article_1    article_2  label\n",
       "2                   1  599580055.0  811835004.0      1\n",
       "6                   1  811835004.0  723529001.0      1\n",
       "7                   1  723529001.0  559630026.0      1\n",
       "8                   1  559630026.0  599580083.0      1\n",
       "9                   1  599580083.0  811927004.0      1\n",
       "...               ...          ...          ...    ...\n",
       "11253154      1368904  884081001.0  794819001.0      1\n",
       "11253155      1368904  794819001.0  762846027.0      1\n",
       "11253156      1368904  866755002.0  840360003.0      1\n",
       "11253157      1368904  840360003.0  866755002.0      1\n",
       "11253158      1368904  866755002.0  882810001.0      1\n",
       "\n",
       "[9989748 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_2</th>\n",
       "      <th>article_1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>869005001.0</td>\n",
       "      <td>599580055.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>866111001.0</td>\n",
       "      <td>599580055.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>856667005.0</td>\n",
       "      <td>599580055.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>739461002.0</td>\n",
       "      <td>599580055.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679011009.0</td>\n",
       "      <td>599580055.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996995</th>\n",
       "      <td>662369058.0</td>\n",
       "      <td>795358001.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996996</th>\n",
       "      <td>841808001.0</td>\n",
       "      <td>795358001.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996997</th>\n",
       "      <td>687635018.0</td>\n",
       "      <td>795358001.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996998</th>\n",
       "      <td>805000002.0</td>\n",
       "      <td>795358001.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996999</th>\n",
       "      <td>800447002.0</td>\n",
       "      <td>795358001.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14997000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            article_2    article_1  label\n",
       "0         869005001.0  599580055.0      0\n",
       "1         866111001.0  599580055.0      0\n",
       "2         856667005.0  599580055.0      0\n",
       "3         739461002.0  599580055.0      0\n",
       "4         679011009.0  599580055.0      0\n",
       "...               ...          ...    ...\n",
       "14996995  662369058.0  795358001.0      0\n",
       "14996996  841808001.0  795358001.0      0\n",
       "14996997  687635018.0  795358001.0      0\n",
       "14996998  805000002.0  795358001.0      0\n",
       "14996999  800447002.0  795358001.0      0\n",
       "\n",
       "[14997000 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to create negative samples, for each article_1 we need to randomly select N article_2 that is not the same as article_1\n",
    "# N is the number of negative samples we want\n",
    "N = 300\n",
    "\n",
    "# create a copy of train\n",
    "train_negative = train.copy()\n",
    "\n",
    "# create a list of all article_id\n",
    "article_ids = train['article_1'].unique()\n",
    "\n",
    "# for each article_id, randomly select N article_id that is not the same as article_id\n",
    "negative_samples = []\n",
    "for article_id in article_ids:\n",
    "    do_not_select = train[train['article_1'] == article_id]['article_2'].unique()\n",
    "    # randomly select N article_id that is not in do_not_select\n",
    "    negative_samples.extend(np.random.choice(np.setdiff1d(article_ids, do_not_select), N, replace=False))\n",
    "# create a dataframe from the negative samples\n",
    "train_negative = pd.DataFrame(negative_samples, columns=['article_2'])\n",
    "train_negative['article_1'] = article_ids.repeat(N)\n",
    "train_negative['label'] = 0\n",
    "\n",
    "train_negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train and train_negative    \n",
    "train = pd.concat([train, train_negative], ignore_index=True)\n",
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 30% of train as valid\n",
    "valid = train.sample(frac=0.3, random_state=42)\n",
    "train = train.drop(valid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(os.path.join(config.data_processed_dir , 'train_pairs.parquet'), index=False)\n",
    "valid.to_parquet(os.path.join(config.data_processed_dir , 'valid_pairs.parquet'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(os.path.join(config.data_processed_dir , 'train_pairs.parquet'))\n",
    "valid = pd.read_parquet(os.path.join(config.data_processed_dir , 'valid_pairs.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_articles(df, articles, article_column, text_column):\n",
    "    df = df.merge(articles, left_on=article_column, right_on='article_id', how='left')\n",
    "    df = df.rename(columns={'text': text_column})\n",
    "    return df.drop(columns=['article_id'])\n",
    "\n",
    "# Use the helper function to merge train and valid with article_1 and article_2\n",
    "train = merge_articles(train, articles, 'article_1', 'text_1')\n",
    "train = merge_articles(train, articles, 'article_2', 'text_2')\n",
    "\n",
    "valid = merge_articles(valid, articles, 'article_1', 'text_1')\n",
    "valid = merge_articles(valid, articles, 'article_2', 'text_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "valid.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35854529196213414\n",
      "0.35856163810206754\n"
     ]
    }
   ],
   "source": [
    "print(valid.label.mean())\n",
    "print(train.label.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, valid], ignore_index=True)\n",
    "item_ids = set(df['article_1'].unique()).union(set(df['article_2'].unique()))\n",
    "# Create a dictionary that maps each item ID to a unique index\n",
    "vocab = {item_id: i for i, item_id in enumerate(item_ids)}\n",
    "num_items = len( set(df['article_1'].unique()).union(set(df['article_2'].unique())) )\n",
    "del item_ids, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        # Create a dictionary that maps each item ID to a unique index\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', truncation=True, padding=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # get article_id1 and article_id2 and labels\n",
    "        article_id1 = row['article_1']\n",
    "        article_id2 = row['article_2']\n",
    "        label = row['label']\n",
    "        # convert to torch tensors\n",
    "        article_id1 = torch.tensor(self.vocab[article_id1], dtype=torch.long)\n",
    "        article_id2 = torch.tensor(self.vocab[article_id2], dtype=torch.long)\n",
    "        label = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        tokens1 = self.tokenizer(row['text_1'], return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "        tokens2 = self.tokenizer(row['text_2'], return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "        return article_id1, article_id2, tokens1['input_ids'].squeeze(), tokens1['attention_mask'].squeeze(), tokens2['input_ids'].squeeze(), tokens2['attention_mask'].squeeze(), label\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "dataset = PairDataset(train, vocab)\n",
    "data_loader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "valid_dataset = PairDataset(valid, vocab)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=4000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5724 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The shape of the 2D attn_mask is torch.Size([1024, 128]), but should be (1024, 1024).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, total_loss\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(valid_data_loader), total_accuracy\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(valid_data_loader)))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m model \u001b[39m=\u001b[39m Item2Vec(num_items\u001b[39m=\u001b[39mnum_items, embedding_dim\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m train_model(model, data_loader, optimizer\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m), num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (item1, item2, input_ids1, attention_mask1, input_ids2, attention_mask2, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     output1 \u001b[39m=\u001b[39m model(item1\u001b[39m.\u001b[39;49mto(device), input_ids1\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mto(device), attention_mask1\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     output2 \u001b[39m=\u001b[39m model(item2\u001b[39m.\u001b[39mto(device), input_ids2\u001b[39m.\u001b[39mto(device), attention_mask2\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     output1 \u001b[39m=\u001b[39m output1\u001b[39m.\u001b[39mview(output1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, output1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])  \u001b[39m# shape: (batch_size, 1, embedding_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, item1, input_ids, attention_mask):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# pass through transforme\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     text1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(input_ids, attention_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     embed1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(item1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Desktop/item2vec/notebooks/01-data-setup.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     embed1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((embed1, text1), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    708\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    716\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    717\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    718\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/Desktop/item2vec/.venv-dev/lib/python3.10/site-packages/torch/nn/functional.py:5318\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5316\u001b[0m     correct_2d_size \u001b[39m=\u001b[39m (tgt_len, src_len)\n\u001b[1;32m   5317\u001b[0m     \u001b[39mif\u001b[39;00m attn_mask\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m correct_2d_size:\n\u001b[0;32m-> 5318\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe shape of the 2D attn_mask is \u001b[39m\u001b[39m{\u001b[39;00mattn_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, but should be \u001b[39m\u001b[39m{\u001b[39;00mcorrect_2d_size\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5319\u001b[0m     attn_mask \u001b[39m=\u001b[39m attn_mask\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m   5320\u001b[0m \u001b[39melif\u001b[39;00m attn_mask\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The shape of the 2D attn_mask is torch.Size([1024, 128]), but should be (1024, 1024)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "class Item2Vec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim):\n",
    "        super().__init__()\n",
    "        # embedding layer\n",
    "        self.embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        transformer_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=4)\n",
    "        self.transformer = nn.TransformerEncoder(transformer_layer, num_layers=4)\n",
    "\n",
    "        # dense layer\n",
    "        self.linear = nn.Linear(embedding_dim * 2, 512)\n",
    "        # activation function\n",
    "        self.act = nn.ReLU()\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # output layer\n",
    "        self.output = nn.Linear(512, embedding_dim)\n",
    "        # output activation\n",
    "        self.output_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, item1, input_ids, attention_mask):\n",
    "        # pass through transforme\n",
    "        text1 = self.transformer(input_ids, attention_mask)\n",
    "\n",
    "        embed1 = self.embeddings(item1)\n",
    "\n",
    "        embed1 = torch.cat((embed1, text1), dim=1)\n",
    "\n",
    "        embed1 = self.dropout(embed1)\n",
    "        # pass through dense layer\n",
    "        dense1 = self.linear(embed1)\n",
    "        # pass through activation function\n",
    "        act1 = self.act(dense1)\n",
    "        # pass through dropout\n",
    "        # pass through output layer\n",
    "        output = self.output(act1)\n",
    "        # pass through output activation\n",
    "        output = self.output_act(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "def loss_function(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)\n",
    "\n",
    "def train_model(model, data_loader, optimizer, num_epochs):\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # switch model to training mode\n",
    "        model.train()\n",
    "        with tqdm(total=len(data_loader)) as progress_bar:\n",
    "            for i, (item1, item2, input_ids1, attention_mask1, input_ids2, attention_mask2, label) in enumerate(data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                output1 = model(item1.to(device), input_ids1.float().to(device), attention_mask1.float().to(device))\n",
    "                output2 = model(item2.to(device), input_ids2.to(device), attention_mask2.to(device))\n",
    "\n",
    "                output1 = output1.view(output1.shape[0], 1, output1.shape[1])  # shape: (batch_size, 1, embedding_dim)\n",
    "                output2 = output2.view(output2.shape[0], output2.shape[1], 1)  # shape: (batch_size, embedding_dim, 1)\n",
    "                # Compute the dot product\n",
    "                output = torch.bmm(output1, output2)  # shape: (batch_size, 1, 1)\n",
    "\n",
    "                # Reshape the output to be two-dimensional\n",
    "                output = output.view(output.shape[0], -1)  # shape: (batch_size, 1)\n",
    "                target = target.view(target.shape[0], -1)  # shape: (batch_size, 1)\n",
    "\n",
    "                loss = loss_function(output, target.float().to(device))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if i % 10 == 0:\n",
    "                    progress_bar.set_postfix(loss=loss.item())\n",
    "                    progress_bar.update(10)\n",
    "\n",
    "               \n",
    "            \n",
    "        # compute total loss and accuracy\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "\n",
    "        # switch model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(total=len(valid_data_loader)) as progress_bar:\n",
    "                for item1, item2, target in valid_data_loader:\n",
    "                    output1 = model(item1.to(device))\n",
    "                    output2 = model(item2.to(device))\n",
    "\n",
    "                    output1 = output1.view(output1.shape[0], 1, output1.shape[1])  # shape: (batch_size, 1, embedding_dim)\n",
    "                    output2 = output2.view(output2.shape[0], output2.shape[1], 1)  # shape: (batch_size, embedding_dim, 1)\n",
    "                    # Compute the dot product\n",
    "                    output = torch.bmm(output1, output2)  # shape: (batch_size, 1, 1)\n",
    "\n",
    "                    # Reshape the output to be two-dimensional\n",
    "                    output = output.view(output.shape[0], -1)  # shape: (batch_size, 1)\n",
    "                    target = target.view(target.shape[0], -1)  # shape: (batch_size, 1)\n",
    "\n",
    "                    loss = loss_function(output, target.float().to(device))\n",
    "                    \n",
    "                    # compute accuracy\n",
    "                    output = output.detach().cpu().numpy()\n",
    "                    target = target.detach().cpu().numpy()\n",
    "                    accuracy = ((output > 0) == target).mean()\n",
    "                    total_loss += loss.item()\n",
    "                    total_accuracy += accuracy\n",
    "                    progress_bar.update(1)\n",
    "\n",
    "        print('Epoch: {}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, total_loss/len(valid_data_loader), total_accuracy/len(valid_data_loader)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Item2Vec(num_items=num_items, embedding_dim=128)\n",
    "train_model(model, data_loader, optimizer=torch.optim.Adam(model.parameters(), lr=0.001), num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
